# LangGraph 核心概念与工程实践指南

> 构建复杂 AI Agent 工作流的完整技术参考

**目标读者:** 从初学者到中级开发者
**核心场景:** 多步骤任务、决策树、人机协作的 AI Agent 工作流
**贯穿案例:** 智能项目管理助手

---

## 第一篇:基础知识篇

建立对 LangGraph 的正确心智模型

### 第 1 章:LangGraph 是什么

#### 1.1 问题背景:为什么需要 LangGraph?

**LLM 应用的演进之路**

在 LLM 应用开发的早期阶段,我们通常从简单的单次调用开始:

```
用户输入 → LLM → 输出结果
```

这种模式适用于简单的问答、文本生成等场景。但当我们尝试构建更复杂的应用时,很快就会遇到局限:

1. **缺乏记忆**: 每次调用都是独立的,无法记住之前的对话或状态
2. **无法决策**: 不能根据输出结果动态选择下一步操作
3. **难以循环**: 无法实现"生成→评估→改进"这样的迭代流程
4. **工具调用受限**: 虽然可以让 LLM 调用工具,但缺乏对调用流程的精细控制

**从 Chain 到 Graph 的必然性**

为了解决单次调用的局限,LangChain 引入了 Chain 的概念,将多个 LLM 调用串联起来:

```
输入 → LLM调用1 → LLM调用2 → LLM调用3 → 输出
```

Chain 虽然实现了基本的串联,但仍然存在本质局限:

| 局限 | 具体表现 | 影响 |
|------|---------|------|
| **线性结构** | 只能按预定顺序执行 | 无法实现条件分支和动态路由 |
| **无状态** | 步骤间靠参数传递 | 难以管理复杂的上下文信息 |
| **不支持循环** | 无法返回到之前的步骤 | 无法实现迭代优化和自我修正 |
| **人机协作困难** | 缺乏中断和恢复机制 | 无法在关键点插入人工审批 |
| **难以调试** | 缺少执行历史 | 问题排查困难,无法回溯状态 |

**真实场景的挑战**

考虑一个智能客服场景:

```
用户咨询 → 理解意图 →
  ├─ 简单问题 → 直接回答
  ├─ 复杂问题 → 查询知识库 → 生成答案 → 质量检查 →
  │                                        ├─ 通过 → 返回
  │                                        └─ 不通过 → 重新生成
  └─ 高风险操作 → 生成方案 → 人工审批 → 执行
```

这样的流程需要:
- **状态管理**: 记住用户信息、历史消息、当前进度
- **条件路由**: 根据意图分类跳转到不同分支
- **循环迭代**: 答案质量不佳时重新生成
- **人机协作**: 高风险操作需要人工介入
- **可恢复性**: 系统重启后能从中断点继续

Chain 无法优雅地实现这些需求,这就是为什么我们需要 LangGraph。

#### 1.2 LangGraph 的定位

**核心定义**

LangGraph 是一个**低级编排框架**,用于构建、管理和部署**长时间运行的、有状态的 AI Agent**。

让我们拆解这个定义:

- **低级编排框架**: 不是高级抽象,而是提供底层控制能力,你可以精确定义每个节点的行为和连接关系
- **长时间运行**: 支持跨多天、多次会话的工作流,不局限于单次请求-响应
- **有状态**: 内置状态管理机制,自动持久化和恢复
- **AI Agent**: 面向 Agent 场景优化,原生支持 LLM、工具调用、人机协作

**核心抽象:有向状态图**

LangGraph 将 Agent 工作流建模为**有向状态图**(Directed Stateful Graph):

```
图 = 节点(Nodes) + 边(Edges) + 状态(State)

节点: 执行具体任务的函数(LLM调用、工具执行、数据处理等)
边: 定义节点间的连接关系(顺序边、条件边)
状态: 在节点间流转的数据结构,记录工作流的完整上下文
```

这个抽象的优势:

1. **可视化**: 工作流结构一目了然,易于理解和沟通
2. **模块化**: 每个节点独立实现,易于测试和复用
3. **灵活性**: 支持任意复杂的控制流(分支、循环、并行)
4. **可追溯**: 状态演进有完整历史,便于调试和审计

**与传统工作流引擎的定位差异**

LangGraph 不是通用工作流引擎(如 Airflow、Temporal),而是**LLM 原生的 Agent 编排框架**:

| 维度 | 传统工作流引擎 | LangGraph |
|------|--------------|-----------|
| **设计目标** | 数据管道、批处理任务 | AI Agent、人机协作工作流 |
| **状态管理** | 通常是任务元数据 | 完整的对话历史、上下文、LLM 输出 |
| **动态性** | 图结构预定义,运行时固定 | 支持 LLM 动态决策路由 |
| **可观测性** | 任务执行日志 | 状态演进历史,支持时间旅行调试 |
| **人机协作** | 通过外部审批系统 | 内置 Interrupt 机制,原生支持 |
| **LLM 集成** | 需要自己封装 | 原生集成,提供工具调用、消息管理等 |

**定位总结**

LangGraph 定位在**可控的 Agent 编排层**:

- 比简单 Chain 更强大:支持复杂控制流、状态管理、人机协作
- 比通用工作流引擎更专注:为 LLM 场景深度优化
- 比全自动 Agent 更可控:开发者精确定义每个决策点

#### 1.3 核心价值

LangGraph 的三大核心价值:

**1. 可控的循环与迭代**

在 LangGraph 中,循环是一等公民:

```
生成初稿 → 质量评估 →
  ├─ 质量合格 → 结束
  └─ 质量不合格 → 改进建议 → 重新生成(返回"生成初稿")
```

实现方式:

```python
# 伪代码
state = {
  draft: "",
  quality_score: 0,
  iteration_count: 0
}

def generate_draft(state):
  draft = LLM.generate(...)
  return {draft: draft, iteration_count: state.iteration_count + 1}

def evaluate_quality(state):
  score = LLM.evaluate(state.draft)
  return {quality_score: score}

def should_continue(state):
  if state.quality_score > 0.8 or state.iteration_count >= 3:
    return "END"
  else:
    return "generate_draft"  # 循环回去

# 构建图
graph.add_node("generate", generate_draft)
graph.add_node("evaluate", evaluate_quality)
graph.add_conditional_edge("evaluate", should_continue)
```

关键价值:
- **有界循环**: 可设置最大迭代次数,避免无限循环
- **状态累积**: 每次迭代的结果都记录在状态中
- **条件终止**: 灵活的终止条件判断

**2. 持久化状态与恢复**

LangGraph 内置 Checkpointer 机制,自动保存每个节点执行后的状态:

```
执行节点A → 保存检查点1 → 执行节点B → 保存检查点2 → ...
```

核心能力:

| 能力 | 说明 | 应用场景 |
|------|------|---------|
| **断点续传** | 系统崩溃后从最后一个检查点恢复 | 长时间运行的任务 |
| **时间旅行** | 回到任意历史检查点查看状态 | 调试、问题分析 |
| **执行历史** | 完整记录状态演进过程 | 审计、回溯分析 |
| **多会话管理** | 每个用户独立的执行线程 | 多用户并发场景 |

存储后端:

```python
# 伪代码
# 开发/测试:内存存储
checkpointer = InMemorySaver()

# 生产环境:持久化存储
checkpointer = SQLiteSaver("checkpoints.db")
# 或
checkpointer = PostgresSaver(connection_string)

graph = graph_builder.compile(checkpointer=checkpointer)
```

**3. 原生的人机协作(Human-in-the-Loop)**

LangGraph 提供 `interrupt_before` 和 `interrupt_after` 机制,让 Agent 在关键点暂停,等待人类输入:

```
准备操作 → interrupt(等待审批) →
  ├─ 人类批准 → 执行操作
  └─ 人类拒绝 → 取消操作
```

实现方式:

```python
# 伪代码
# 在"执行删除"节点前中断
graph = graph_builder.compile(
  checkpointer=checkpointer,
  interrupt_before=["execute_deletion"]
)

# 执行到删除节点前会自动暂停
result = graph.invoke({...}, config=config)
# result.status = "interrupted"

# 获取当前状态,展示给用户
current_state = graph.get_state(config)

# 用户审批后,继续执行
graph.invoke(None, config=config)  # 从中断点继续
```

人机协作的典型场景:
- **风险操作审批**: 删除数据、发送邮件、执行支付
- **不确定性决策**: LLM 置信度低时,让人类选择
- **创意性工作**: 设计方案生成后,让人类修改和确认
- **异常处理**: 遇到预期外的情况,请求人工介入

#### 1.4 适用场景 vs 不适用场景

**✅ 适用场景**

| 场景类型 | 具体示例 | 为什么适合 LangGraph |
|---------|---------|-------------------|
| **多步骤推理** | 复杂问题分解、逐步求解 | 需要状态在多步骤间传递 |
| **迭代优化** | 文章写作→评审→改进→再评审 | 需要循环和质量门控 |
| **条件分支** | 客服:简单问题直接答、复杂问题转人工 | 需要动态路由 |
| **工具编排** | 调研助手:搜索→提取→分析→总结 | 需要管理多工具调用流程 |
| **人机协作** | 法律文书生成→律师审核→修改→定稿 | 需要 interrupt 机制 |
| **长时间运行** | 项目管理:创建任务→分解→分配→跟踪(跨多天) | 需要持久化状态 |
| **状态机** | 订单处理:待支付→待发货→待收货→已完成 | 天然映射到状态图 |

**❌ 不适用场景**

| 场景类型 | 为什么不适合 | 推荐方案 |
|---------|------------|----------|
| **简单单次调用** | LangGraph 太重,引入不必要的复杂度 | 直接调用 LLM API 或使用简单 Chain |
| **纯数据转换管道** | 不需要 LLM 动态决策,只需固定的数据流 | Airflow、Prefect 等数据管道工具 |
| **高性能批处理** | LangGraph 优化目标是灵活性而非吞吐量 | Spark、Flink 等批处理框架 |
| **实时低延迟** | Checkpointer 持久化会引入延迟 | 内存计算、流处理框架 |
| **完全自主 Agent** | 你需要 LangGraph 提供的可控性 | ReAct Agent、AutoGPT 等 |

**判断标准**

问自己这些问题:

1. **是否需要多步骤?** 如果是单次 LLM 调用就能完成,不需要 LangGraph
2. **是否需要状态管理?** 如果步骤间需要共享复杂的上下文,使用 LangGraph
3. **是否需要条件分支或循环?** 如果控制流是动态的,使用 LangGraph
4. **是否需要人工介入?** 如果关键点需要人类决策,使用 LangGraph
5. **是否需要可恢复性?** 如果任务可能长时间运行且不能丢失进度,使用 LangGraph

**最佳实践建议**

- **从简单开始**: 先用简单 Chain 实现,确实遇到局限时再迁移到 LangGraph
- **渐进式采用**: 可以在 LangGraph 节点中调用现有的 Chain
- **混合使用**: 简单部分用 Chain,复杂部分用 LangGraph,不是非此即彼

**小结**

LangGraph 不是银弹,它解决的是**复杂 Agent 工作流的可控编排**问题。理解它的适用场景,可以帮助你在合适的时候选择合适的工具,避免过度设计或功能不足。

---
